
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Crawling Berita &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Tugas Crawling';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Vector Space Model" href="Support%20Vector%20Model.html" />
    <link rel="prev" title="Menu Utama" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Menu Utama
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Crawling Berita</a></li>

<li class="toctree-l1"><a class="reference internal" href="Support%20Vector%20Model.html">Vector Space Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Logistic%20Regression.html">Klasifikasi Berita</a></li>

<li class="toctree-l1"><a class="reference internal" href="Graph%20dan%20Summarization.html">Summarization</a></li>


<li class="toctree-l1"><a class="reference internal" href="Keyword.html">Keyword Extraction</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FTugas Crawling.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Tugas Crawling.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling Berita</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Crawling Berita</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling">Konsep Crawling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tool-dan-library-yang-digunakan">Tool dan Library Yang Digunakan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-penggunaan">Contoh Penggunaan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tips-penting">Tips Penting:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling">Proses Crawling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#library-yang-digunakan">Library yang digunakan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-implementasi">Code Implementasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-code">Penjelasan Code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-crawling">Output Crawling</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>Nama : Ahmad Nasrudin Jamil</p>
<p>Nim  : 210411100098</p>
<p>Kelas : Pencarian dan Penambangan Web B</p>
<section class="tex2jax_ignore mathjax_ignore" id="crawling-berita">
<h1>Crawling Berita<a class="headerlink" href="#crawling-berita" title="Link to this heading">#</a></h1>
<section id="konsep-crawling">
<h2>Konsep Crawling<a class="headerlink" href="#konsep-crawling" title="Link to this heading">#</a></h2>
<p><strong>Pengertian</strong></p>
<p>Crawling adalah proses otomatis yang dilakukan oleh perangkat lunak, yang biasa disebut <strong>web crawler</strong> atau <strong>spider</strong>, untuk menelusuri dan mengumpulkan informasi dari halaman-halaman web di internet. Web crawler secara sistematis mengikuti tautan dari satu halaman ke halaman lainnya, mengindeks konten yang ditemukan, dan menyimpannya dalam basis data atau sistem pengindeksan. Proses ini memungkinkan mesin pencari, seperti Google, untuk membangun indeks besar dari halaman web sehingga pengguna dapat mencari informasi secara efisien.</p>
<p>Dalam crawling, web crawler dimulai dari satu atau lebih URL yang disebut <strong>seed</strong>, kemudian mengakses halaman tersebut, dan memproses informasi yang tersedia, termasuk tautan ke halaman lain. Crawler kemudian mengikuti tautan tersebut untuk menemukan halaman web lainnya. Informasi yang diambil oleh crawler biasanya mencakup teks, metadata, dan struktur halaman web.</p>
<p>Crawler diatur dengan kebijakan tertentu, seperti <strong>robots.txt</strong> yang ditetapkan oleh pemilik situs web untuk membatasi bagian situs mana yang boleh atau tidak boleh diakses oleh crawler. Tujuan dari crawling adalah untuk memastikan bahwa mesin pencari atau aplikasi lain yang memerlukan data web memiliki akses ke konten yang relevan dan up-to-date.</p>
<p><strong>Tujuan</strong></p>
<p>Tujuan dari crawling adalah untuk mengumpulkan, mengindeks, dan memperbarui informasi dari halaman-halaman web di internet. Secara lebih rinci, tujuan-tujuan crawling meliputi:</p>
<ol class="arabic simple">
<li><p><strong>Membangun Indeks Mesin Pencari:</strong> Web crawler digunakan oleh mesin pencari seperti Google untuk mengumpulkan data dari halaman web. Informasi ini kemudian diindeks, sehingga ketika pengguna melakukan pencarian, mesin pencari dapat menemukan dan menampilkan hasil yang relevan dengan cepat.</p></li>
<li><p><strong>Memastikan Data Terkini:</strong> Crawling memungkinkan mesin pencari untuk terus memperbarui indeksnya dengan data terbaru dari web. Ini penting untuk memberikan hasil pencarian yang akurat dan up-to-date kepada pengguna.</p></li>
<li><p><strong>Menemukan Halaman Web Baru:</strong> Crawling membantu mesin pencari menemukan halaman web baru yang belum terindeks sebelumnya, sehingga lebih banyak konten yang dapat diakses oleh pengguna melalui pencarian.</p></li>
<li><p><strong>Mengumpulkan Data untuk Analisis:</strong> Perusahaan atau organisasi dapat menggunakan crawler untuk mengumpulkan data dari web untuk berbagai tujuan, seperti analisis pasar, pemantauan kompetitor, atau penelitian.</p></li>
<li><p><strong>Mengoptimalkan Pengalaman Pengguna:</strong> Dengan memastikan bahwa konten yang diindeks relevan dan berkualitas, crawling membantu mesin pencari memberikan pengalaman pencarian yang lebih baik bagi pengguna.</p></li>
<li><p><strong>Pemantauan Situs Web:</strong> Crawling juga digunakan untuk memantau situs web, seperti untuk mengidentifikasi masalah teknis, memastikan kepatuhan terhadap standar SEO, atau melacak perubahan konten.</p></li>
</ol>
<p><strong>Jenis-Jenis</strong></p>
<ol class="arabic simple">
<li><p><strong>News Crawling</strong> adalah proses pengumpulan data dari situs berita dan portal berita online. Tujuannya adalah untuk memastikan bahwa mesin pencari memiliki informasi terkini dan relevan dari berbagai sumber berita sehingga pengguna dapat menemukan berita terbaru dengan cepat.</p></li>
<li><p><strong>Social Media Crawling</strong> adalah proses pengumpulan data dari platform media sosial seperti Twitter, Facebook, dan Instagram. Tujuannya adalah untuk mengumpulkan data yang dapat digunakan untuk analisis tren, pemantauan merek, atau riset pemasaran, serta memahami opini publik atau reaksi terhadap peristiwa tertentu.</p></li>
<li><p><strong>Video Crawling</strong> adalah proses pengumpulan informasi dari situs-situs berbagi video seperti YouTube dan Vimeo. Tujuannya adalah untuk mengindeks video untuk mesin pencari video atau untuk analisis tren, rekomendasi konten, atau pengelompokan video berdasarkan topik.</p></li>
<li><p><strong>Image Crawling</strong> adalah proses pengumpulan gambar dari web. Tujuannya adalah untuk mengindeks gambar untuk mesin pencari gambar, melatih model pengenalan gambar, atau untuk riset yang memerlukan pengumpulan data visual.</p></li>
<li><p><strong>Email Crawling</strong> adalah proses pengumpulan alamat email dari berbagai situs web. Tujuannya adalah untuk mengumpulkan alamat email untuk keperluan pemasaran, membangun daftar pelanggan, atau dalam beberapa kasus, untuk aktivitas spam.</p></li>
</ol>
<p><strong>Contoh Web Crawling</strong></p>
<ol class="arabic simple">
<li><p><strong>Duckduc Bot</strong> adalah bot web yang digunakan oleh mesin pencari DuckDuckGo. Tujuannya adalah untuk mengindeks halaman web sehingga informasi tersebut dapat muncul dalam hasil pencarian DuckDuckGo, yang menonjolkan privasi pengguna sebagai keunggulan utamanya.</p></li>
<li><p><strong>Baiduspider</strong> adalah bot web yang dimiliki oleh Baidu, mesin pencari terbesar di Tiongkok. Tujuannya adalah untuk mengindeks halaman-halaman web, terutama untuk pasar Tiongkok, agar konten tersebut dapat diakses melalui hasil pencarian Baidu.</p></li>
<li><p><strong>Alexabot</strong> adalah bot yang digunakan oleh Alexa Internet, anak perusahaan Amazon, untuk mengumpulkan data tentang lalu lintas web. Tujuannya adalah untuk menyediakan analisis, peringkat, dan statistik web yang digunakan oleh layanan Alexa untuk memantau kinerja situs web.</p></li>
<li><p><strong>Yahoo! Slurp Bot</strong> adalah crawler yang digunakan oleh Yahoo! untuk mengindeks halaman web. Tujuannya adalah memastikan konten yang diindeks dapat ditemukan dan ditampilkan dalam hasil pencarian Yahoo!, yang merupakan salah satu mesin pencari terkemuka di masa lalu.</p></li>
<li><p><strong>Yandex Bot</strong> adalah bot web yang digunakan oleh Yandex, mesin pencari terbesar di Rusia. Tujuannya adalah untuk mengindeks halaman web agar informasi tersebut tersedia dalam hasil pencarian Yandex, yang melayani pengguna di Rusia dan negara-negara berbahasa Rusia lainnya.</p></li>
<li><p><strong>Bingbot</strong> adalah bot web milik Microsoft yang digunakan oleh mesin pencari Bing. Tujuannya adalah untuk mengindeks konten dari halaman web di seluruh dunia sehingga informasi tersebut dapat ditemukan dalam hasil pencarian Bing.</p></li>
<li><p><strong>Facebook External Hit</strong> Hit adalah bot yang digunakan oleh Facebook untuk merayapi halaman web ketika pengguna membagikan tautan di platform tersebut. Tujuannya adalah untuk mengumpulkan metadata dan gambar dari halaman web guna membuat pratinjau (preview) yang menarik saat tautan dibagikan di Facebook.</p></li>
</ol>
<p><strong>Cara Kerja</strong></p>
<p>Cara kerja crawling melibatkan beberapa langkah utama yang dilakukan oleh program komputer yang disebut crawler atau spider. Berikut adalah penjelasan langkah demi langkah mengenai cara kerja crawling:</p>
<ol class="arabic simple">
<li><p><strong>Inisialisasi URL</strong>: Crawling dimulai dengan daftar URL awal yang disebut sebagai “seed URLs.” URL ini biasanya diambil dari halaman-halaman web yang sudah diketahui penting atau populer, seperti halaman beranda situs terkenal.</p></li>
<li><p><strong>Mengunjungi Halaman Web</strong>: Crawler mengunjungi setiap URL dalam daftar seed. Saat mengunjungi halaman, crawler membaca dan mengunduh konten halaman web tersebut, termasuk teks, gambar, dan elemen-elemen lainnya.</p></li>
<li><p><strong>Ekstraksi Tautan (Link Extraction)</strong>: Setelah mengunduh halaman, crawler mengekstrak semua tautan (link) yang ada di dalamnya. Tautan-tautan ini menunjuk ke halaman lain baik di dalam situs yang sama maupun di situs web lain. Tautan baru ini ditambahkan ke daftar URL yang harus dikunjungi.</p></li>
<li><p><strong>Penyimpanan dan Indeksasi</strong>: Crawler menyimpan salinan halaman web yang diunduh dan mengirimkan informasi yang relevan ke mesin indeks. Mesin indeks mengolah informasi ini untuk mempermudah pencarian di masa mendatang, misalnya dengan menganalisis kata kunci, metadata, dan struktur halaman.</p></li>
<li><p><strong>Mengikuti Tautan</strong>: Crawler kemudian mengunjungi tautan-tautan baru yang telah diekstrak. Proses ini diulang terus menerus, menciptakan siklus yang memungkinkan crawler untuk menjelajahi seluruh web secara bertahap.</p></li>
<li><p><strong>Penyaringan (Filtering)</strong>: Tidak semua halaman yang ditemukan oleh crawler diindeks. Crawler menggunakan berbagai aturan untuk menyaring halaman yang dianggap tidak relevan, seperti halaman yang berisi spam, duplikat konten, atau halaman dengan sedikit konten.</p></li>
<li><p><strong>Pemutakhiran (Update Crawling)</strong>: Crawlers juga secara berkala mengunjungi ulang halaman yang sudah diindeks untuk memperbarui informasi yang ada. Halaman yang sering berubah mungkin lebih sering dikunjungi ulang oleh crawler.</p></li>
<li><p><strong>Prioritas (Crawling Priority)</strong>: Crawler biasanya memprioritaskan halaman berdasarkan berbagai faktor, seperti popularitas, kualitas tautan, atau seberapa sering konten halaman diperbarui.</p></li>
<li><p><strong>Kepatuhan terhadap Robot.txt</strong>: Sebelum mengunjungi halaman, crawler memeriksa file <code class="docutils literal notranslate"><span class="pre">robots.txt</span></code> di setiap situs untuk melihat apakah ada aturan yang membatasi bagian mana dari situs yang boleh atau tidak boleh diakses.</p></li>
<li><p><strong>Penanganan Kesalahan</strong>: Crawler juga menangani berbagai kesalahan yang mungkin terjadi, seperti halaman tidak ditemukan (404 error), waktu tunggu (timeout), atau masalah akses lainnya.</p></li>
</ol>
<p>Dengan mengikuti langkah-langkah ini, crawler dapat menjelajahi web secara efisien, mengumpulkan data yang dibutuhkan, dan memastikan mesin pencari memiliki indeks yang up-to-date dan relevan untuk digunakan dalam menampilkan hasil pencarian kepada pengguna.</p>
</section>
<section id="teknik-dan-cara-crawling-menggunakan-python">
<h2>Teknik dan Cara Crawling Menggunakan Python<a class="headerlink" href="#teknik-dan-cara-crawling-menggunakan-python" title="Link to this heading">#</a></h2>
<p>Crawling menggunakan Python melibatkan beberapa teknik yang memungkinkan pengumpulan data dari situs web secara otomatis. Teknik dasar termasuk penggunaan pustaka <code class="docutils literal notranslate"><span class="pre">requests</span></code> untuk mengunduh halaman web, di mana kontennya dapat diambil dan diproses. Setelah halaman diunduh, pustaka <code class="docutils literal notranslate"><span class="pre">BeautifulSoup</span></code> sering digunakan untuk memparsing dokumen HTML atau XML, memungkinkan ekstraksi elemen spesifik seperti tautan atau teks. Untuk tugas crawling yang lebih kompleks dan terstruktur, <code class="docutils literal notranslate"><span class="pre">Scrapy</span></code> adalah framework populer yang menawarkan kemampuan untuk membangun spider yang dapat menjelajahi dan mengumpulkan data dari banyak halaman web secara efisien. Untuk situs web dinamis yang mengandalkan JavaScript, <code class="docutils literal notranslate"><span class="pre">Selenium</span></code> digunakan untuk mengotomatisasi browser dan mengambil konten yang di-render, memastikan data dari situs dinamis dapat diakses. Selain itu, teknik tambahan seperti menambahkan <code class="docutils literal notranslate"><span class="pre">User-Agent</span></code> dan jeda antar permintaan dengan <code class="docutils literal notranslate"><span class="pre">time.sleep</span></code> digunakan untuk menghindari pemblokiran oleh situs web, menjaga agar proses crawling terlihat lebih alami dan menghindari deteksi.</p>
</section>
<section id="tool-dan-library-yang-digunakan">
<h2>Tool dan Library Yang Digunakan<a class="headerlink" href="#tool-dan-library-yang-digunakan" title="Link to this heading">#</a></h2>
<p>Sebgai contoh disini menggunakan Beautiful Soup untuk crawling website berita, maka harus mempersiapkan beberapa tools dan library. Berikut langkah-langkahnya:</p>
<ol class="arabic">
<li><p><strong>Install Python</strong>:
Memastikan Python terinstal di sistem, jika belum maka dapat mengunduhnya dari <a class="reference external" href="https://www.python.org/downloads/">python.org</a>.</p></li>
<li><p><strong>Install Library yang Dibutuhkan</strong>:</p>
<ul class="simple">
<li><p><strong>Requests</strong>: Untuk mengirim permintaan HTTP ke situs web yang ingin dicrawl.</p></li>
<li><p><strong>Beautiful Soup</strong>: Untuk memparsing HTML dan mengekstrak data yang diinginkan.</p></li>
</ul>
<p>Menginstal kedua library ini menggunakan pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>requests
pip<span class="w"> </span>install<span class="w"> </span>beautifulsoup4
</pre></div>
</div>
</li>
<li><p><strong>Library Tambahan (Opsional)</strong>:
<strong>lxml</strong> atau <strong>html5lib</strong>: Untuk parsing HTML yang lebih kuat, maka dapat menginstal parser ini. Beautiful Soup mendukung berbagai parser, tetapi <code class="docutils literal notranslate"><span class="pre">lxml</span></code> atau <code class="docutils literal notranslate"><span class="pre">html5lib</span></code> sering digunakan untuk parsing yang lebih kompleks.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>lxml
pip<span class="w"> </span>install<span class="w"> </span>html5lib
</pre></div>
</div>
</li>
<li><p><strong>IDE atau Text Editor</strong>:
Bisa juga menggunakan IDE atau text editor seperti PyCharm, VSCode, atau bahkan Notepad++ untuk menulis skrip Python.</p></li>
</ol>
<section id="contoh-penggunaan">
<h3>Contoh Penggunaan<a class="headerlink" href="#contoh-penggunaan" title="Link to this heading">#</a></h3>
<p>Berikut adalah contoh sederhana menggunakan Requests dan Beautiful Soup untuk melakukan crawling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c1"># URL yang ingin di crawl</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://example.com&#39;</span>

<span class="c1"># Mengirimkan permintaan HTTP ke URL</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># Memastikan permintaan berhasil</span>
<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="c1"># Parsing HTML menggunakan Beautiful Soup</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    
    <span class="c1"># Mengekstrak data yang diinginkan, misalnya semua judul artikel</span>
    <span class="k">for</span> <span class="n">title</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;h1&#39;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">title</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Failed to retrieve the webpage.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="tips-penting">
<h3>Tips Penting:<a class="headerlink" href="#tips-penting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Patuhilah Robots.txt</strong>: Sebelum melakukan crawling, pastikan untuk memeriksa file <code class="docutils literal notranslate"><span class="pre">robots.txt</span></code> situs web tersebut untuk melihat aturan yang harus dipatuhi.</p></li>
<li><p><strong>Rate Limiting</strong>: Untuk menghindari pembatasan atau pemblokiran, tambahkan jeda waktu antara permintaan.</p></li>
<li><p><strong>Menggunakan User-Agent</strong>: Kadang-kadang perlu untuk menyetel <code class="docutils literal notranslate"><span class="pre">User-Agent</span></code> header dalam permintaan HTTP untuk menghindari deteksi sebagai bot.</p></li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="proses-crawling">
<h1>Proses Crawling<a class="headerlink" href="#proses-crawling" title="Link to this heading">#</a></h1>
<section id="library-yang-digunakan">
<h2>Library yang digunakan<a class="headerlink" href="#library-yang-digunakan" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">csv</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="code-implementasi">
<h2>Code Implementasi<a class="headerlink" href="#code-implementasi" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membuat variabel list kosong menampung hasil berita</span>
<span class="n">article_result</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterasi page dari 1 sampai 10</span>
<span class="k">for</span> <span class="n">page_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://indeks.kompas.com/?page=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page_num</span><span class="p">)</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articleItem&#39;</span><span class="p">)</span>

    <span class="c1"># Iterasi artikel dalam setiap halaman</span>
    <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
        <span class="n">article_url</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;article-link&#39;</span><span class="p">)[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articleTitle&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">category</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articlePost-subtitle&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articlePost-date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="n">cPage</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">article_url</span><span class="p">)</span>
        <span class="n">cSoup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">cPage</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

        <span class="n">content_paragraphs</span> <span class="o">=</span> <span class="n">cSoup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;read__content&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
        <span class="n">content</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">content_paragraphs</span><span class="p">])</span>

        <span class="c1"># Menggabungkan detail artikel ke dalam list hasil</span>
        <span class="n">article_result</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">date</span><span class="p">,</span> <span class="n">category</span><span class="p">])</span>

<span class="c1"># Konversi hasil ke Dataframe</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">article_result</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="penjelasan-code">
<h2>Penjelasan Code<a class="headerlink" href="#penjelasan-code" title="Link to this heading">#</a></h2>
<p>Berikut ini adalah penjelasan untuk kode diatas:</p>
<ol class="arabic">
<li><p>Inisialisasi List Kosong untuk Menyimpan Hasil</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">article_result</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">article_result</span></code> adalah list kosong yang akan digunakan untuk menyimpan data dari setiap artikel yang berhasil diambil dari beberapa halaman web.</p>
</li>
<li><p>Iterasi Halaman dari 1 hingga 10</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">page_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://indeks.kompas.com/?page=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page_num</span><span class="p">)</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articleItem&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">page_num</span> <span class="pre">in</span> <span class="pre">range(1,</span> <span class="pre">11)</span></code></strong>: Loop ini digunakan untuk mengiterasi halaman web dari 1 hingga 10. <code class="docutils literal notranslate"><span class="pre">range(1,</span> <span class="pre">11)</span></code> menghasilkan angka dari 1 sampai 10.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">url</span> <span class="pre">=</span> <span class="pre">&quot;https://indeks.kompas.com/?page={}&quot;.format(page_num)</span></code></strong>: Untuk setiap nomor halaman (<code class="docutils literal notranslate"><span class="pre">page_num</span></code>), kode ini membangun URL dengan menambahkan nomor halaman sebagai parameter di akhir URL.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">page</span> <span class="pre">=</span> <span class="pre">requests.get(url)</span></code></strong>: Mengirimkan permintaan HTTP GET ke URL yang dibentuk untuk setiap halaman, dan respons HTML disimpan di variabel <code class="docutils literal notranslate"><span class="pre">page</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">soup</span> <span class="pre">=</span> <span class="pre">BeautifulSoup(page.text,</span> <span class="pre">'html.parser')</span></code></strong>: Mem-parsing konten HTML dari <code class="docutils literal notranslate"><span class="pre">page</span></code> menggunakan BeautifulSoup untuk diolah lebih lanjut.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">articles</span> <span class="pre">=</span> <span class="pre">soup.find_all('div',</span> <span class="pre">class_='articleItem')</span></code></strong>: Mencari semua elemen <code class="docutils literal notranslate"><span class="pre">div</span></code> dengan class <code class="docutils literal notranslate"><span class="pre">articleItem</span></code> dalam halaman web tersebut. Setiap elemen <code class="docutils literal notranslate"><span class="pre">div</span></code> ini dianggap mewakili satu artikel di halaman tersebut.</p></li>
</ul>
</li>
<li><p>Mengiterasi Artikel dalam Setiap Halaman</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
    <span class="n">article_url</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;article-link&#39;</span><span class="p">)[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articleTitle&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articlePost-subtitle&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;articlePost-date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">article</span> <span class="pre">in</span> <span class="pre">articles</span></code></strong>: Loop ini mengiterasi setiap artikel yang ditemukan dalam halaman yang sedang diproses.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">article_url</span> <span class="pre">=</span> <span class="pre">article.find('a',</span> <span class="pre">class_='article-link')['href']</span></code></strong>: Mengambil URL lengkap dari artikel dengan mencari elemen <code class="docutils literal notranslate"><span class="pre">a</span></code> yang memiliki class <code class="docutils literal notranslate"><span class="pre">article-link</span></code> dan mengambil atribut <code class="docutils literal notranslate"><span class="pre">href</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">title</span> <span class="pre">=</span> <span class="pre">article.find('h2',</span> <span class="pre">class_='articleTitle').text.strip()</span></code></strong>: Mengambil judul artikel dari elemen <code class="docutils literal notranslate"><span class="pre">h2</span></code> dengan class <code class="docutils literal notranslate"><span class="pre">articleTitle</span></code> dan menghapus spasi yang tidak perlu menggunakan <code class="docutils literal notranslate"><span class="pre">strip()</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">category</span> <span class="pre">=</span> <span class="pre">article.find('div',</span> <span class="pre">class_='articlePost-subtitle').text.strip()</span></code></strong>: Mengambil kategori artikel dari elemen <code class="docutils literal notranslate"><span class="pre">div</span></code> dengan class <code class="docutils literal notranslate"><span class="pre">articlePost-subtitle</span></code> dan membersihkannya dari spasi yang tidak perlu.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">date</span> <span class="pre">=</span> <span class="pre">article.find('div',</span> <span class="pre">class_='articlePost-date').text.strip()</span></code></strong>: Mengambil tanggal artikel dari elemen <code class="docutils literal notranslate"><span class="pre">div</span></code> dengan class <code class="docutils literal notranslate"><span class="pre">articlePost-date</span></code>.</p></li>
</ul>
</li>
<li><p>Mengambil Konten dari Setiap Artikel</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cPage</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">article_url</span><span class="p">)</span>
<span class="n">cSoup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">cPage</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="n">content_paragraphs</span> <span class="o">=</span> <span class="n">cSoup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;read__content&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="n">content</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">content_paragraphs</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">cPage</span> <span class="pre">=</span> <span class="pre">requests.get(article_url)</span></code></strong>: Mengirimkan permintaan HTTP GET ke URL artikel yang diambil pada langkah sebelumnya.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">cSoup</span> <span class="pre">=</span> <span class="pre">BeautifulSoup(cPage.text,</span> <span class="pre">'html.parser')</span></code></strong>: Mem-parsing halaman artikel untuk mengambil konten utamanya.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">content_paragraphs</span> <span class="pre">=</span> <span class="pre">cSoup.find('div',</span> <span class="pre">class_='read__content').find_all('p')</span></code></strong>: Mencari elemen <code class="docutils literal notranslate"><span class="pre">div</span></code> dengan class <code class="docutils literal notranslate"><span class="pre">read__content</span></code> yang biasanya menyimpan isi utama dari artikel, dan mengambil semua paragraf (<code class="docutils literal notranslate"><span class="pre">&lt;p&gt;</span></code>).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">content</span> <span class="pre">=</span> <span class="pre">&quot;\n&quot;.join([p.text.strip()</span> <span class="pre">for</span> <span class="pre">p</span> <span class="pre">in</span> <span class="pre">content_paragraphs])</span></code></strong>: Menggabungkan teks dari setiap paragraf menjadi satu string besar, dipisahkan oleh newline (<code class="docutils literal notranslate"><span class="pre">\n</span></code>).</p></li>
</ul>
</li>
<li><p>Menyimpan Data Artikel ke dalam List</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">article_result</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">date</span><span class="p">,</span> <span class="n">category</span><span class="p">])</span>
</pre></div>
</div>
<p>Data artikel yang terdiri dari judul (<code class="docutils literal notranslate"><span class="pre">title</span></code>), konten (<code class="docutils literal notranslate"><span class="pre">content</span></code>), tanggal (<code class="docutils literal notranslate"><span class="pre">date</span></code>), dan kategori (<code class="docutils literal notranslate"><span class="pre">category</span></code>) disimpan sebagai satu entri dalam list <code class="docutils literal notranslate"><span class="pre">article_result</span></code>.</p>
</li>
<li><p>Mengonversi Hasil Menjadi DataFrame</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">article_result</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Setelah semua halaman dan artikel diproses, <code class="docutils literal notranslate"><span class="pre">article_result</span></code> diubah menjadi DataFrame dengan menggunakan <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, yang memudahkan analisis data lebih lanjut. Kolom DataFrame diberi nama <code class="docutils literal notranslate"><span class="pre">title</span></code>, <code class="docutils literal notranslate"><span class="pre">content</span></code>, <code class="docutils literal notranslate"><span class="pre">date</span></code>, dan <code class="docutils literal notranslate"><span class="pre">category</span></code>.</p>
</li>
</ol>
</section>
<section id="output-crawling">
<h2>Output Crawling<a class="headerlink" href="#output-crawling" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-e362cbec-8e55-4fb0-a685-f54cf073ae85" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>content</th>
      <th>date</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Damkarmat Ungkap Penyebab Buaya yang Muncul di...</td>
      <td>MAKASSAR, KOMPAS.com - Seekor buaya berukuran ...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Perbedaan Saham dan Reksadana: Pilihan Investa...</td>
      <td>JAKARTA, KOMPAS.com - Saham dan reksadana adal...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Persib Vs Persebaya, Munster Terus Pantau Kond...</td>
      <td>KOMPAS.com – Pelatih Persebaya Surabaya Paul M...</td>
      <td>16/10/2024</td>
      <td>BOLA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Suku Lingon, si Mata Biru yang Menghuni Belant...</td>
      <td>KOMPAS.com - Suku Lingon adalah salah satu suk...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Simak Cara Cek Kode SWIFT BCA untuk Transfer A...</td>
      <td>JAKARTA, KOMPAS.com – Dalam transaksi perbanka...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Petugas Sortir dan Lipat 2 Juta Surat Suara Pi...</td>
      <td>SUKABUMI, KOMPAS.com - Petugas sortir dan lipa...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>6</th>
      <td>12 Ragam Bubur di Indonesia dan Asalnya, Ada B...</td>
      <td>KOMPAS.com - Bubur merupakan salah satu makana...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Tanggal 18 Oktober 2024 Memperingati Hari Apa?</td>
      <td>KOMPAS.com – Tanggal 18 Oktober 2024 jatuh pad...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Komposisi Kabinet yang Beragam Diapresiasi, Be...</td>
      <td>JAKARTA, KOMPAS.com - Direktur Eksekutif Algor...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Dimyati Ingatkan Warga Banten Tak Pilih Pemimp...</td>
      <td>JAKARTA, KOMPAS.com - Calon wakil gubenur Bant...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2 Cara Ganti Kartu ATM BRI yang Sudah "Expired"</td>
      <td>JAKARTA, KOMPAS.com - Kartu ATM yang kedaluwar...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Potensi Laut Banten Masih Terabaikan, Apa Solu...</td>
      <td>JAKARTA, KOMPAS.com - Potensi Laut di Provinsi...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Kemenperin: Indonesia Baru Wajibkan 130 SNI, N...</td>
      <td>JAKARTA, KOMPAS.com - Kepala Badan Standardisa...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Khawatir Sekolah Terganggu, MK Minta Instansi ...</td>
      <td>JAKARTA, KOMPAS.com - Mahkamah Konstitusi (MK)...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Bagaimana Cara Transfer Shopeepay ke Gopay?</td>
      <td>KOMPAS.com - Transfer saldo ke sesama dompet e...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Cara Membuat Adonan Kulit Kue Sus, Isi dengan ...</td>
      <td>KOMPAS.com - Kue sus merupakan jajanan pasar y...</td>
      <td>16/10/2024</td>
      <td>FOOD</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Ramai Dapat Ucapan Selamat Bertugas, Giring: T...</td>
      <td>KOMPAS.com – Penyanyi Giring Ganesha menjadi s...</td>
      <td>16/10/2024</td>
      <td>HYPE</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Panglima TNI Ingatkan Ancaman Negara Tak Hanya...</td>
      <td>JAKARTA, KOMPAS.com - Panglima TNI Jenderal TN...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Roberto Mancini: Arab Saudi Seharusnya Menang ...</td>
      <td>KOMPAS.com - Pelatih timnas Arab Saudi Roberto...</td>
      <td>16/10/2024</td>
      <td>BOLA</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Jenguk Bebingah Sang Tansahayu, Jokowi Akui Be...</td>
      <td>JAKARTA, KOMPAS.com - Presiden Joko Widodo men...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Kapan Kondom Digunakan? Berikut Penjelasannya…</td>
      <td>KOMPAS.com - Kondom adalah jenis kontrasepsi y...</td>
      <td>16/10/2024</td>
      <td>HEALTH</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Rano Karno Ingin Silat Betawi Masuk ke Estraku...</td>
      <td>JAKARTA, KOMPAS.com - Calon wakil gubernur nom...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Angkat Hilirisasi Nikel, Bahlil Lahadalia Dapa...</td>
      <td>DEPOK, KOMPAS.com - Bahlil Lahadalia, Menteri ...</td>
      <td>16/10/2024</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Anggota DPR Pertanyakan Pemecatan Ipda Rudy So...</td>
      <td>JAKARTA, KOMPAS.com - Anggota Fraksi Gerindra ...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Bawaslu Ingatkan Paslon Dilarang Beri Uang ata...</td>
      <td>JAKARTA, KOMPAS.com - Badan Pengawasan Pemilih...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Jadi Produser di Rumah Produksi, Ria Ricis Eng...</td>
      <td>JAKARTA, KOMPAS.com - YouTuber yang kini menja...</td>
      <td>16/10/2024</td>
      <td>HYPE</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Sosok Wanita Calo Akpol Tipu "Crazy Rich" Maka...</td>
      <td>KOMPAS.com - Seorang wanita berinisial AFR mel...</td>
      <td>16/10/2024</td>
      <td>REGIONAL</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Ridwan Kamil Nilai Semua Cagub Harus Bersinerg...</td>
      <td>JAKARTA, KOMPAS.com - Calon gubernur Jakarta n...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>28</th>
      <td>MK Tolak Provisi Penundaan Penyidikan Dirut Ta...</td>
      <td>JAKARTA, KOMPAS.com - Mahkamah Konstitusi (MK)...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Dito Ariotedjo Sebut Menteri dan Wamen Kabinet...</td>
      <td>JAKARTA, KOMPAS.com - Menteri Pemuda dan Olahr...</td>
      <td>16/10/2024</td>
      <td>NEWS</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e362cbec-8e55-4fb0-a685-f54cf073ae85')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e362cbec-8e55-4fb0-a685-f54cf073ae85 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e362cbec-8e55-4fb0-a685-f54cf073ae85');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_filename</span> <span class="o">=</span> <span class="s2">&quot;berita_crawling_kompas.csv&quot;</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_filename</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data berita telah disimpan ke </span><span class="si">{</span><span class="n">csv_filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data berita telah disimpan ke berita_crawling_kompas.csv
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Menu Utama</p>
      </div>
    </a>
    <a class="right-next"
       href="Support%20Vector%20Model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Vector Space Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Crawling Berita</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling">Konsep Crawling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tool-dan-library-yang-digunakan">Tool dan Library Yang Digunakan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-penggunaan">Contoh Penggunaan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tips-penting">Tips Penting:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling">Proses Crawling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#library-yang-digunakan">Library yang digunakan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-implementasi">Code Implementasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-code">Penjelasan Code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-crawling">Output Crawling</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>